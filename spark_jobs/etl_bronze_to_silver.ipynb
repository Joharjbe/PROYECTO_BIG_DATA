{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ba7807",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a839cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# para matriz de correlación\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a72e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/06/25 11:20:11 WARN Utils: Your hostname, MacBook-Pro-de-johar.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.20 instead (on interface en0)\n",
      "25/06/25 11:20:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/25 11:20:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 54076)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/johar/Desktop/Big Data/25-1/yelp_project/yelp_project/lib/python3.11/site-packages/pyspark/accumulators.py\", line 299, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/johar/Desktop/Big Data/25-1/yelp_project/yelp_project/lib/python3.11/site-packages/pyspark/accumulators.py\", line 271, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/Users/johar/Desktop/Big Data/25-1/yelp_project/yelp_project/lib/python3.11/site-packages/pyspark/accumulators.py\", line 275, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/johar/Desktop/Big Data/25-1/yelp_project/yelp_project/lib/python3.11/site-packages/pyspark/serializers.py\", line 597, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# creamos la sesión e indicamos que corra de forma local\n",
    "spark = (SparkSession.builder\n",
    "        .appName(\"Yelp ETL\") # *\n",
    "\n",
    "        # por defecto spark usa una cantidad de memoria 1GB aprox para el ejecutor\n",
    "        # durante el desarrollo no fue suficente y el valor óptimo fue de 8g\n",
    "        # además usar particiones mayores a 10 arruinaban el procesp\n",
    "        .config(\"spark.executor.memory\", \"8g\")  # aumentamos la memoria del ejecutor\n",
    "        .config(\"spark.driver.memory\", \"8g\")  # aumentamos la memoria del driver\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"10\")  # ajustamos el número de particiones\n",
    "        \n",
    "        .master(\"local[*]\") # *\n",
    "        .getOrCreate()) # *\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897bd75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# rutas bronze\n",
    "path_bronze_base = \"../data/bronze/\"\n",
    "\n",
    "path_business = f\"{path_bronze_base}yelp_academic_dataset_business.json\"\n",
    "path_checkin = f\"{path_bronze_base}yelp_academic_dataset_checkin.json\"\n",
    "path_review = f\"{path_bronze_base}yelp_academic_dataset_review.json\"\n",
    "path_tip = f\"{path_bronze_base}yelp_academic_dataset_tip.json\"\n",
    "path_user = f\"{path_bronze_base}yelp_academic_dataset_user.json\"\n",
    "\n",
    "# read\n",
    "df_business = spark.read.json(path_business)\n",
    "df_checkin = spark.read.json(path_checkin)\n",
    "df_review = spark.read.json(path_review)\n",
    "df_tip = spark.read.json(path_tip)\n",
    "df_user = spark.read.json(path_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dcbe7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.0\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b5a42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+-------------+--------------+--------------------+-----------+------------+-----+-----+\n",
      "|             address|          attributes|         business_id|          categories|          city|               hours|is_open|     latitude|     longitude|                name|postal_code|review_count|stars|state|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+-------------+--------------+--------------------+-----------+------------+-----+-----+\n",
      "|1616 Chapala St, ...|{NULL, NULL, NULL...|Pns2l4eNsfO8kk83d...|Doctors, Traditio...| Santa Barbara|                NULL|      0|   34.4266787|  -119.7111968|Abby Rappoport, L...|      93101|           7|  5.0|   CA|\n",
      "|87 Grasso Plaza S...|{NULL, NULL, NULL...|mpf3x-BjTdTEA3yCZ...|Shipping Centers,...|        Affton|{8:0-18:30, 0:0-0...|      1|    38.551126|    -90.335695|       The UPS Store|      63123|          15|  3.0|   MO|\n",
      "|5255 E Broadway Blvd|{NULL, NULL, NULL...|tUFrWirKiKi_TAnsV...|Department Stores...|        Tucson|{8:0-23:0, 8:0-22...|      0|    32.223236|   -110.880452|              Target|      85711|          22|  3.5|   AZ|\n",
      "|         935 Race St|{NULL, NULL, u'no...|MTSW4McQd7CbVtyjq...|Restaurants, Food...|  Philadelphia|{7:0-21:0, 7:0-20...|      1|   39.9555052|   -75.1555641|  St Honore Pastries|      19107|          80|  4.0|   PA|\n",
      "|       101 Walnut St|{NULL, NULL, NULL...|mWMc6_wTdE0EUBKIG...|Brewpubs, Breweri...|    Green Lane|{12:0-22:0, NULL,...|      1|   40.3381827|   -75.4716585|Perkiomen Valley ...|      18054|          13|  4.5|   PA|\n",
      "|       615 S Main St|{NULL, NULL, u'no...|CF33F8-E6oudUQ46H...|Burgers, Fast Foo...|  Ashland City|{9:0-0:0, 0:0-0:0...|      1|    36.269593|    -87.058943|      Sonic Drive-In|      37015|           6|  2.0|   TN|\n",
      "|8522 Eager Road, ...|{NULL, NULL, NULL...|n_0UpQx1hsNbnPUSl...|Sporting Goods, F...|     Brentwood|{10:0-18:0, 0:0-0...|      1|    38.627695|    -90.340465|     Famous Footwear|      63144|          13|  2.5|   MO|\n",
      "|  400 Pasadena Ave S|                NULL|qkRM_2X51Yqxk3btl...|Synagogues, Relig...|St. Petersburg|{9:0-17:0, 9:0-17...|      1|     27.76659|    -82.732983|      Temple Beth-El|      33707|           5|  3.5|   FL|\n",
      "|   8025 Mackenzie Rd|{NULL, NULL, u'fu...|k0hlBqXX-Bt0vf1op...|Pubs, Restaurants...|        Affton|                NULL|      0|   38.5651648|   -90.3210868|Tsevi's Pub And G...|      63123|          19|  3.0|   MO|\n",
      "| 2312 Dickerson Pike|{NULL, NULL, u'no...|bBDDEgkFA1Otx9Lfe...|Ice Cream & Froze...|     Nashville|{6:0-16:0, 0:0-0:...|      1|   36.2081024|   -86.7681696|      Sonic Drive-In|      37207|          10|  1.5|   TN|\n",
      "|21705 Village Lak...|{NULL, NULL, NULL...|UJsufbvfyfONHeWdv...|Department Stores...| Land O' Lakes|{9:30-21:30, 9:30...|      1|28.1904587953|-82.4573802199|           Marshalls|      34639|           6|  3.5|   FL|\n",
      "|                    |{NULL, NULL, 'non...|eEOYSgkmpB90uNA7l...|Vietnamese, Food,...|     Tampa Bay|{11:0-14:0, 11:0-...|      1|   27.9552692|   -82.4563199|Vietnamese Food T...|      33602|          10|  4.0|   FL|\n",
      "|        8901 US 31 S|{NULL, NULL, 'non...|il_Ro8jwPlHresjw9...|American (Traditi...|  Indianapolis|{6:0-22:0, 6:0-22...|      1|39.6371332838| -86.127217412|             Denny's|      46227|          28|  2.5|   IN|\n",
      "|   15 N Missouri Ave|{NULL, NULL, NULL...|jaxMSoInw8Poo3XeM...|General Dentistry...|    Clearwater|{NULL, 7:30-15:30...|      1|    27.966235|    -82.787412|        Adams Dental|      33755|          10|  5.0|   FL|\n",
      "|       2575 E Bay Dr|{NULL, NULL, u'no...|0bPLkL0QhhPO5kt1_...|Food, Delis, Ital...|         Largo|{10:0-20:0, 10:0-...|      0|   27.9161159|   -82.7604608|Zio's Italian Market|      33771|         100|  4.5|   FL|\n",
      "|         205 Race St|{NULL, NULL, 'ful...|MUTTqe8uqyMdBl186...|Sushi Bars, Resta...|  Philadelphia|{13:30-23:0, NULL...|      1|    39.953949|   -75.1432262|            Tuna Bar|      19106|         245|  4.0|   PA|\n",
      "|     625 N Stone Ave|{NULL, NULL, NULL...|rBmpy_Y1UbBx8ggHl...|Automotive, Auto ...|        Tucson|{8:0-17:0, 0:0-0:...|      1|   32.2298719|  -110.9723419|Arizona Truck Out...|      85705|          10|  4.5|   AZ|\n",
      "|        712 Adams St|{NULL, NULL, NULL...|M0XSSHqrASOnhgbWD...|Vape Shops, Tobac...|   New Orleans|{10:0-19:0, 10:0-...|      1|29.9414679565| -90.129952757|      Herb Import Co|      70118|           5|  4.0|   LA|\n",
      "|     1241 Airline Dr|                NULL|8wGISYjYkE2tSqn3c...|Automotive, Car R...|        Kenner|{8:0-17:0, 8:0-17...|      1|    29.981183|   -90.2540123|    Nifty Car Rental|      70062|          14|  3.5|   LA|\n",
      "|       1224 South St|{NULL, NULL, u'no...|ROeacJQwBeh05Rqg7...| Korean, Restaurants|  Philadelphia|{11:30-20:30, 11:...|      1|    39.943223|    -75.162568|                 BAP|      19147|         205|  4.5|   PA|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+-------------+--------------+--------------------+-----------+------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "root\n",
      " |-- address: string (nullable = true)\n",
      " |-- attributes: struct (nullable = true)\n",
      " |    |-- AcceptsInsurance: string (nullable = true)\n",
      " |    |-- AgesAllowed: string (nullable = true)\n",
      " |    |-- Alcohol: string (nullable = true)\n",
      " |    |-- Ambience: string (nullable = true)\n",
      " |    |-- BYOB: string (nullable = true)\n",
      " |    |-- BYOBCorkage: string (nullable = true)\n",
      " |    |-- BestNights: string (nullable = true)\n",
      " |    |-- BikeParking: string (nullable = true)\n",
      " |    |-- BusinessAcceptsBitcoin: string (nullable = true)\n",
      " |    |-- BusinessAcceptsCreditCards: string (nullable = true)\n",
      " |    |-- BusinessParking: string (nullable = true)\n",
      " |    |-- ByAppointmentOnly: string (nullable = true)\n",
      " |    |-- Caters: string (nullable = true)\n",
      " |    |-- CoatCheck: string (nullable = true)\n",
      " |    |-- Corkage: string (nullable = true)\n",
      " |    |-- DietaryRestrictions: string (nullable = true)\n",
      " |    |-- DogsAllowed: string (nullable = true)\n",
      " |    |-- DriveThru: string (nullable = true)\n",
      " |    |-- GoodForDancing: string (nullable = true)\n",
      " |    |-- GoodForKids: string (nullable = true)\n",
      " |    |-- GoodForMeal: string (nullable = true)\n",
      " |    |-- HairSpecializesIn: string (nullable = true)\n",
      " |    |-- HappyHour: string (nullable = true)\n",
      " |    |-- HasTV: string (nullable = true)\n",
      " |    |-- Music: string (nullable = true)\n",
      " |    |-- NoiseLevel: string (nullable = true)\n",
      " |    |-- Open24Hours: string (nullable = true)\n",
      " |    |-- OutdoorSeating: string (nullable = true)\n",
      " |    |-- RestaurantsAttire: string (nullable = true)\n",
      " |    |-- RestaurantsCounterService: string (nullable = true)\n",
      " |    |-- RestaurantsDelivery: string (nullable = true)\n",
      " |    |-- RestaurantsGoodForGroups: string (nullable = true)\n",
      " |    |-- RestaurantsPriceRange2: string (nullable = true)\n",
      " |    |-- RestaurantsReservations: string (nullable = true)\n",
      " |    |-- RestaurantsTableService: string (nullable = true)\n",
      " |    |-- RestaurantsTakeOut: string (nullable = true)\n",
      " |    |-- Smoking: string (nullable = true)\n",
      " |    |-- WheelchairAccessible: string (nullable = true)\n",
      " |    |-- WiFi: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- hours: struct (nullable = true)\n",
      " |    |-- Friday: string (nullable = true)\n",
      " |    |-- Monday: string (nullable = true)\n",
      " |    |-- Saturday: string (nullable = true)\n",
      " |    |-- Sunday: string (nullable = true)\n",
      " |    |-- Thursday: string (nullable = true)\n",
      " |    |-- Tuesday: string (nullable = true)\n",
      " |    |-- Wednesday: string (nullable = true)\n",
      " |-- is_open: long (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/25 11:20:23 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 6:=====>                                                    (1 + 9) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+--------------------+-----------+------------------+-----------------+------------------+--------------------+------------------+-----------------+------------------+------+\n",
      "|summary|          address|         business_id|          categories|       city|           is_open|         latitude|         longitude|                name|       postal_code|     review_count|             stars| state|\n",
      "+-------+-----------------+--------------------+--------------------+-----------+------------------+-----------------+------------------+--------------------+------------------+-----------------+------------------+------+\n",
      "|  count|           150346|              150346|              150243|     150346|            150346|           150346|            150346|              150346|            150346|           150346|            150346|150346|\n",
      "|   mean|7369.333333333333|                NULL|                NULL|       NULL|0.7961502135075094|36.67115006414571|-89.35733948971429|              1252.4| 45177.81755426108|44.86656113232144|3.5967235576603303|  NULL|\n",
      "| stddev|8738.777641447725|                NULL|                NULL|       NULL|0.4028599390900636|5.872758917014048| 14.91850167993062|   811.1275005954503|26395.882085856472|121.1201357011708|0.9744207509201364|  NULL|\n",
      "|    min|                 |---kPU91CF4Lq2-Wl...|3D Printing, Loca...|AB Edmonton|                 0|        27.555127|       -120.095137|        Grow Academy|                  |                5|               1.0|    AB|\n",
      "|    max|  ​185 E State St|zzyx5x0Z7xXWWvWnZ...|Zoos, Tours, Arts...|    ​Lithia|                 1|       53.6791969|    -73.2004570502|​​Transformationa...|           T9E 0V3|             7568|               5.0|   XMS|\n",
      "+-------+-----------------+--------------------+--------------------+-----------+------------------+-----------------+------------------+--------------------+------------------+-----------------+------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_business.show()\n",
    "df_business.printSchema()\n",
    "df_business.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfab75c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         business_id|                date|\n",
      "+--------------------+--------------------+\n",
      "|---kPU91CF4Lq2-Wl...|2020-03-13 21:10:...|\n",
      "|--0iUa4sNDFiZFrAd...|2010-09-13 21:43:...|\n",
      "|--30_8IhuyMHbSOcN...|2013-06-14 23:29:...|\n",
      "|--7PUidqRWpRSpXeb...|2011-02-15 17:12:...|\n",
      "|--7jw19RH9JKXgFoh...|2014-04-21 20:42:...|\n",
      "|--8IbOsAAxjKRoYsB...|2015-06-06 01:03:...|\n",
      "|--9osgUCSDUWUkoTL...|2015-06-13 02:00:...|\n",
      "|--ARBQr1WMsTWiwOK...|2014-12-12 00:44:...|\n",
      "|--FWWsIwxRwuw9vIM...|2010-09-11 16:28:...|\n",
      "|--FcbSxK1AoEtEAxO...|2017-08-18 19:43:...|\n",
      "|--LC8cIrALInl2vyo...|2017-01-12 19:10:...|\n",
      "|--MbOh2O1pATkXa7x...|2013-04-21 01:52:...|\n",
      "|--N9yp3ZWqQIm7DqK...|2012-10-06 20:46:...|\n",
      "|--O3ip9NpXTKD4oBS...|2010-04-17 21:07:...|\n",
      "|--OS_I7dnABrXvRCC...| 2018-05-11 18:23:36|\n",
      "|--S43ruInmIsGrnnk...|2010-08-29 01:17:...|\n",
      "|--SJXpAa0E-GCp2sm...|2014-04-06 22:23:...|\n",
      "|--Sd93OFWITqDHifM...|2013-01-09 17:42:...|\n",
      "|--ZVrH2X2QXBFdCil...|2010-08-12 18:21:...|\n",
      "|--ZWv8kGlM2YL58uK...|2010-10-13 18:41:...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+\n",
      "|summary|         business_id|                date|\n",
      "+-------+--------------------+--------------------+\n",
      "|  count|              131930|              131930|\n",
      "|   mean|                NULL|                NULL|\n",
      "| stddev|                NULL|                NULL|\n",
      "|    min|---kPU91CF4Lq2-Wl...|2009-12-30 02:53:...|\n",
      "|    max|zzyx5x0Z7xXWWvWnZ...| 2022-01-19 01:15:21|\n",
      "+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_checkin.show()\n",
    "df_checkin.printSchema()\n",
    "df_checkin.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac3a845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|XQfwVwDr-v0ZS3_Cb...|   0|2018-07-07 22:09:11|    0|KU_O5udG6zpxOg-Vc...|  3.0|If you decide to ...|     0|mh_-eMZ6K5RLWhZyI...|\n",
      "|7ATYjTIgM3jUlt4UM...|   1|2012-01-03 15:28:18|    0|BiTunyQ73aT9WBnpR...|  5.0|I've taken a lot ...|     1|OyoGAe7OKpv6SyGZT...|\n",
      "|YjUWPpI6HXG530lwP...|   0|2014-02-05 20:30:30|    0|saUsX_uimxRlCVr67...|  3.0|Family diner. Had...|     0|8g_iMtfSiwikVnbP2...|\n",
      "|kxX2SOes4o-D3ZQBk...|   1|2015-01-04 00:01:03|    0|AqPFMleE6RsU23_au...|  5.0|Wow!  Yummy, diff...|     1|_7bHUi9Uuf5__HHc_...|\n",
      "|e4Vwtrqf-wpJfwesg...|   1|2017-01-14 20:54:15|    0|Sx8TMOWLNuJBWer-0...|  4.0|Cute interior and...|     1|bcjbaE6dDog4jkNY9...|\n",
      "|04UD14gamNjLY0IDY...|   1|2015-09-23 23:10:31|    2|JrIxlS1TzJ-iCu79u...|  1.0|I am a long term ...|     1|eUta8W_HdHMXPzLBB...|\n",
      "|gmjsEdUsKpj9Xxu6p...|   0|2015-01-03 23:21:18|    2|6AxgBCNX_PNTOxmbR...|  5.0|Loved this tour! ...|     0|r3zeYsv1XFBRA4dJp...|\n",
      "|LHSTtnW3YHCeUkRDG...|   0|2015-08-07 02:29:16|    0|_ZeMknuYdlQcUqng_...|  5.0|Amazingly amazing...|     2|yfFzsLmaWF2d4Sr0U...|\n",
      "|B5XSoSG3SfvQGtKEG...|   0|2016-03-30 22:46:33|    1|ZKvDG2sBvHVdF5oBN...|  3.0|This easter inste...|     1|wSTuiTk-sKNdcFypr...|\n",
      "|gebiRewfieSdtt17P...|   0|2016-07-25 07:31:06|    0|pUycOfUwM8vqX7KjR...|  3.0|Had a party of 6 ...|     0|59MxRhNVhU9MYndMk...|\n",
      "|uMvVYRgGNXf5boolA...|   0|2015-06-21 14:48:06|    0|rGQRf8UafX7OTlMNN...|  5.0|My experience wit...|     2|1WHRWwQmZOZDAhp2Q...|\n",
      "|EQ-TZ2eeD_E0BHuvo...|   0|2015-08-19 14:31:45|    0|l3Wk_mvAog6XANIuG...|  4.0|Locals recommende...|     0|ZbqSHbgCjzVAqaa7N...|\n",
      "|lj-E32x9_FA7GmUrB...|   0|2014-06-27 22:44:01|    0|XW_LfMv0fV21l9c6x...|  4.0|Love going here f...|     0|9OAtfnWag-ajVxRbU...|\n",
      "|RZtGWDLCAtuipwaZ-...|   0|2009-10-14 19:57:14|    0|8JFGBuHMoiNDyfcxu...|  4.0|Good food--loved ...|     0|smOvOajNG0lS4Pq7d...|\n",
      "|otQS34_MymijPTdNB...|   0|2011-10-27 17:12:05|    2|UBp0zWyH60Hmw6Fsa...|  4.0|The bun makes the...|     0|4Uh27DgGzsp6PqrH9...|\n",
      "|BVndHaLihEYbr76Z0...|   0|2014-10-11 16:22:06|    0|OAhBYw8IQ6wlfw1ow...|  5.0|Great place for b...|     0|1C2lxzUo1Hyye4RFI...|\n",
      "|YtSqYv1Q_pOltsVPS...|   0|2013-06-24 11:21:25|    0|oyaMhzBSwfGgemSGu...|  5.0|Tremendous servic...|     0|Dd1jQj7S-BFGqRbAp...|\n",
      "|rBdG_23USc7DletfZ...|   0|2014-08-10 19:41:43|    0|LnGZB0fjfgeVDVz5I...|  4.0|The hubby and I h...|     1|j2wlzrntrbKwyOcOi...|\n",
      "|CLEWowfkj-wKYJlQD...|   1|2016-03-07 00:02:18|    0|u2vzZaOqJ2feRshaa...|  5.0|I go to blow bar ...|     2|NDZvyYHTUWWu-kqgQ...|\n",
      "|eFvzHawVJofxSnD7T...|   0|2014-11-12 15:30:27|    0|Xs8Z8lmKkosqW5mw_...|  5.0|My absolute favor...|     0|IQsF3Rc6IgCzjVV9D...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:==============================================>         (33 + 7) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+-------------------+-------------------+--------------------+------------------+----------------------+------------------+--------------------+\n",
      "|summary|         business_id|              cool|               date|              funny|           review_id|             stars|                  text|            useful|             user_id|\n",
      "+-------+--------------------+------------------+-------------------+-------------------+--------------------+------------------+----------------------+------------------+--------------------+\n",
      "|  count|             6990280|           6990280|            6990280|            6990280|             6990280|           6990280|               6990280|           6990280|             6990280|\n",
      "|   mean|                NULL|0.4986175088837643|               NULL|0.32655959417934616|                NULL|  3.74858374771826|                  NULL|1.1846089140921394|                NULL|\n",
      "| stddev|                NULL|2.1724598202111864|               NULL| 1.6887290985540495|                NULL|1.4787045052556855|                  NULL| 3.253766966933363|                NULL|\n",
      "|    min|---kPU91CF4Lq2-Wl...|                -1|2005-02-16 03:23:22|                 -1|---4VcQZzy_vIIifU...|               1.0|  !\\nMilk Bar is po...|                -1|---1lKK3aKOuomHnw...|\n",
      "|    max|zzyx5x0Z7xXWWvWnZ...|               404|2022-01-19 19:48:45|                792|zzzz1ADBqBEVyfX4l...|               5.0|＼(^o^)／\\nThey hav...|              1182|zzzUFM4HFe0SFG0bP...|\n",
      "+-------+--------------------+------------------+-------------------+-------------------+--------------------+------------------+----------------------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_review.show()\n",
    "df_review.printSchema()\n",
    "df_review.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644d223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-------------------+--------------------+--------------------+\n",
      "|         business_id|compliment_count|               date|                text|             user_id|\n",
      "+--------------------+----------------+-------------------+--------------------+--------------------+\n",
      "|3uLgwr0qeCNMjKenH...|               0|2012-05-18 02:17:21|Avengers time wit...|AGNUgVwnZUey3gcPC...|\n",
      "|QoezRbYQncpRqyrLH...|               0|2013-02-05 18:35:10|They have lots of...|NBN4MgHP9D3cw--Sn...|\n",
      "|MYoRNLb5chwjQe3c_...|               0|2013-08-18 00:56:08|It's open even wh...|-copOvldyKh1qr-vz...|\n",
      "|hV-bABTK-glh5wj31...|               0|2017-06-27 23:05:38|Very decent fried...|FjMQVZjSqY8syIO-5...|\n",
      "|_uN0OudeJ3Zl_tf6n...|               0|2012-10-06 19:43:09|Appetizers.. plat...|ld0AperBXk1h6Ubqm...|\n",
      "+--------------------+----------------+-------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- compliment_count: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=====>                                                   (1 + 9) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|summary|         business_id|    compliment_count|               date|                text|             user_id|\n",
      "+-------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|  count|              908915|              908915|             908915|              908915|              908915|\n",
      "|   mean|                NULL|0.012524823553357574|               NULL|1.792114762548089...|                NULL|\n",
      "| stddev|                NULL| 0.12076339327984326|               NULL|1.411112521356809...|                NULL|\n",
      "|    min|---kPU91CF4Lq2-Wl...|                   0|2009-04-16 13:11:49|                   !|---r61b7EpVPkb4UV...|\n",
      "|    max|zzyx5x0Z7xXWWvWnZ...|                   6|2022-01-19 20:38:55|to the apple gor...|zzxZW6U5lCCQQeVfL...|\n",
      "+-------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_tip.show(5)\n",
    "df_tip.printSchema()\n",
    "df_tip.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59dfdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+-----+--------------------+----+--------------------+-----+---------+------------+------+--------------------+-------------------+\n",
      "|average_stars|compliment_cool|compliment_cute|compliment_funny|compliment_hot|compliment_list|compliment_more|compliment_note|compliment_photos|compliment_plain|compliment_profile|compliment_writer| cool|               elite|fans|             friends|funny|     name|review_count|useful|             user_id|      yelping_since|\n",
      "+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+-----+--------------------+----+--------------------+-----+---------+------------+------+--------------------+-------------------+\n",
      "|         3.91|            467|             56|             467|           250|             18|             65|            232|              180|             844|                55|              239| 5994|                2007| 267|NSCy54eWehBJyZdG2...| 1259|   Walker|         585|  7217|qVc8ODYU5SZjKXVBg...|2007-01-25 16:47:26|\n",
      "|         3.74|           3131|            157|            3131|          1145|            251|            264|           1847|             1946|            7054|               184|             1521|27281|2009,2010,2011,20...|3138|ueRPE0CX75ePGMqOF...|13066|   Daniel|        4333| 43091|j14WgRoU_-2ZE1aw1...|2009-01-25 04:35:42|\n",
      "|         3.32|            119|             17|             119|            89|              3|             13|             66|               18|              96|                10|               35| 1003|2009,2010,2011,20...|  52|LuO3Bn4f3rlhyHIaN...| 1010|    Steph|         665|  2086|2WnXYQFK0hXEoTxPt...|2008-07-25 10:41:00|\n",
      "|         4.27|             26|              6|              26|            24|              2|              4|             12|                9|              16|                 1|               10|  299|      2009,2010,2011|  28|enx1vVPnfdNUdPho6...|  330|     Gwen|         224|   512|SZDeASXq7o05mMNLs...|2005-11-29 04:38:33|\n",
      "|         3.54|              0|              0|               0|             1|              0|              1|              1|                0|               1|                 0|                0|    7|                    |   1|PBK4q9KEEBHhFvSXC...|   15|    Karen|          79|    29|hA5lMy-EnncsH4JoR...|2007-01-05 19:40:59|\n",
      "|         3.85|           2543|            361|            2543|          1713|            147|            163|           1212|              323|            5696|               191|              815|11211|2006,2007,2008,20...|1357|xBDpTUbai0DXrvxCe...| 9940|     Jane|        1221| 14953|q_QQ5kBBwlCcbL1s4...|2005-03-14 20:26:35|\n",
      "|         2.75|              0|              0|               0|             0|              0|              0|              0|                0|               1|                 0|                0|    0|                    |   1|HDAQ74AEznP-YsMk1...|    1|      Rob|          12|     6|cxuxXkcihfCbqt5By...|2009-02-24 03:09:06|\n",
      "|         3.73|             12|              0|              12|             4|              0|              7|              8|                0|               6|                 2|                5|  143|                    |  23|y2GyxJF5VQWohxgw_...|  102|     Mike|         358|   399|E9kcWJdJUHuTKfQur...|2008-12-11 22:11:56|\n",
      "|         4.04|              5|              3|               5|             2|              0|              0|              3|                1|               4|                 0|                3|   46|                    |   7|tOQDlz36rI__SOsbL...|   40| Rachelle|          40|   109|lO1iq-f75hnPNZkTy...|2008-12-29 22:40:56|\n",
      "|          3.4|              3|              0|               3|             0|              0|              0|              1|                0|               6|                 0|                0|   23|                    |   4|gy5fWeSv3Gamuq9Ox...|   20|     John|         109|   154|AUi8MPWJ0mLkMfwbu...|2010-01-07 18:32:04|\n",
      "|          4.0|              0|              0|               0|             0|              0|              0|              0|                0|               0|                 0|                0|    1|                    |   1|Vq4Pc81l6MWTnc-h4...|    0|    Chris|           4|     1|iYzhPPqnrjJkg1JHZ...|2010-11-03 18:59:20|\n",
      "|         3.89|             36|              3|              36|            23|              5|              9|             31|                7|              41|                 1|               24|  573| 2009,2010,2011,2012|  31|6tbXpUIU6upoeqWND...|  487|     Ryan|         535|  1130|xoZvMJPDW6Q9pDAXI...|2009-05-27 06:12:10|\n",
      "|         4.51|              0|              0|               0|             4|              0|              0|              1|                0|               5|                 0|                1|   27|                    |   4|zkK6c9BcDyqreU0fq...|    3| Charlene|          37|    63|vVukUtqoLF5BvH_Vt...|2011-01-29 17:18:59|\n",
      "|         3.08|              0|              0|               0|             0|              0|              0|              0|                0|               0|                 0|                0|    0|                    |   0|f0mdrhyxVZ0TsFZD5...|    3|    Kenny|          11|    30|_crIokUeTCHVK_JVO...|2009-10-07 17:23:44|\n",
      "|         4.29|              2|              0|               2|             1|              0|              0|              1|                0|               0|                 0|                0|   13|                    |   1|piejMEdRkGB7-1aL4...|    3|   Teresa|           7|    18|1McG5Rn_UDkmlkZOr...|2009-05-26 16:11:11|\n",
      "|         3.75|            221|             22|             221|           212|             34|             17|             67|               17|             158|                17|               45| 1297|2007,2008,2009,20...|  44|j3MBGSLaXMlhLZNeA...| 1138|   Eugene|         682|  1819|SgiBkhXeqIKl1PlFp...|2006-08-25 16:47:25|\n",
      "|         4.15|              2|              0|               2|             0|              0|              1|              6|                0|               2|                 0|                1|   19|                    |   1|hJiJzw6obCmbGAfwr...|    2| Jennifer|          25|    29|fJZO_skqpnhk1kvom...|2008-07-14 16:01:36|\n",
      "|         3.84|             66|              0|              66|            15|              0|              1|             12|               12|              33|                 0|                1|   29|                    |   9|EPBLDry-ObheloH-N...|   29|  Ronskee|          37|    56|x7YtLnBW2dUnrrpwa...|2010-05-06 00:40:56|\n",
      "|         4.11|            808|             29|             808|          1020|             23|             79|            144|              723|             407|                68|              587| 4149|2010,2011,2012,20...| 131|dLts9bY66tXEFqYG0...| 3714|Catherine|         607|  4573|QF1Kuhs8iwLWANNZx...|2009-04-27 20:25:54|\n",
      "|          3.6|              0|              0|               0|             1|              0|              0|              2|                0|               4|                 0|                1|   44|                    |   4|Ynu2Z2L8Wv2fbTwQ_...|   52|       AJ|         133|   201|VcLRGCG_VbAo8MxOm...|2009-07-11 16:47:38|\n",
      "+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+-----+--------------------+----+--------------------+-----+---------+------------+------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "root\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- compliment_cool: long (nullable = true)\n",
      " |-- compliment_cute: long (nullable = true)\n",
      " |-- compliment_funny: long (nullable = true)\n",
      " |-- compliment_hot: long (nullable = true)\n",
      " |-- compliment_list: long (nullable = true)\n",
      " |-- compliment_more: long (nullable = true)\n",
      " |-- compliment_note: long (nullable = true)\n",
      " |-- compliment_photos: long (nullable = true)\n",
      " |-- compliment_plain: long (nullable = true)\n",
      " |-- compliment_profile: long (nullable = true)\n",
      " |-- compliment_writer: long (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- elite: string (nullable = true)\n",
      " |-- fans: long (nullable = true)\n",
      " |-- friends: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- yelping_since: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=====================================================>  (25 + 1) / 26]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+------------------+-----------------+------------------+-------------------+-----------------+------------------+-----------------+------------------+--------------------+------------------+------------+------------------+-----------------+--------------------+-------------------+\n",
      "|summary|     average_stars|   compliment_cool|    compliment_cute|  compliment_funny|    compliment_hot|    compliment_list|    compliment_more|   compliment_note|compliment_photos|  compliment_plain| compliment_profile|compliment_writer|              cool|            elite|              fans|             friends|             funny|        name|      review_count|           useful|             user_id|      yelping_since|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+------------------+-----------------+------------------+-------------------+-----------------+------------------+-----------------+------------------+--------------------+------------------+------------+------------------+-----------------+--------------------+-------------------+\n",
      "|  count|           1987897|           1987897|            1987897|           1987897|           1987897|            1987897|            1987897|           1987897|          1987897|           1987897|            1987897|          1987897|           1987897|          1987897|           1987897|             1987897|           1987897|     1987897|           1987897|          1987897|             1987897|            1987897|\n",
      "|   mean|  3.63049415035087|2.8293080577112395|0.13364927860950543|2.8293080577112395|1.8070724992290847|0.06390723463036566|0.29226313033321144|1.4431346292086562|1.226859339291724|3.0118411567601338|0.17931764070271247|1.056448095650831|23.792913817969442|2017.220760233918|1.4657404282012598|                NULL|16.970536199813168|         NaN|23.394409267683386|42.29633527290398|                NULL|               NULL|\n",
      "| stddev|1.1833369995975145| 96.66385446471259| 11.356823097797161| 96.66385446471259| 73.60184094967366|  10.04362659411937| 12.824667119930178| 60.16790049259038| 95.1575129716489|119.38980389840354| 15.155253377853501|32.17972805346817| 565.3512954713351| 4.09363504648036| 18.13075272385579|                NULL| 407.8034374841018|         NaN| 82.56699161797889|641.4805967755902|                NULL|               NULL|\n",
      "|    min|               1.0|                 0|                  0|                 0|                 0|                  0|                  0|                 0|                0|                 0|                  0|                0|                 0|                 |                 0|---2PmXbF47D870st...|                 0|       Chris|                 0|                0|---1lKK3aKOuomHnw...|2004-10-12 08:46:11|\n",
      "|    max|               5.0|             49967|              13654|             49967|             25784|              12669|              13501|             59031|            82630|            101097|              14180|            15934|            199878|             2021|             12497|zzzOOwSYzuTPvsafS...|            185823|Ｊｏａｎｎｅ|             17473|           206296|zzzUFM4HFe0SFG0bP...|2022-01-19 17:15:47|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+------------------+-----------------+------------------+-------------------+-----------------+------------------+-----------------+------------------+--------------------+------------------+------------+------------------+-----------------+--------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_user.show()\n",
    "df_user.printSchema()\n",
    "df_user.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c0b7a",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e890dfac",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af2ceb",
   "metadata": {},
   "source": [
    "- review_id\n",
    "- user_id\n",
    "- business_id\n",
    "- stars\n",
    "- text\n",
    "- date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3beaed2",
   "metadata": {},
   "source": [
    "stars: Calificación individual de cada reseña (1-5 estrellas, dada por un usuario para un negocio).\n",
    "\n",
    "será renombrada al final a reviews_stars para evitar conflicto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63f800fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_review = df_review.select(\"review_id\", \"user_id\", \"business_id\", \"stars\", \"text\", \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcfc8d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:==============================================>         (33 + 7) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+------------------+----------------------+-------------------+\n",
      "|summary|           review_id|             user_id|         business_id|             stars|                  text|               date|\n",
      "+-------+--------------------+--------------------+--------------------+------------------+----------------------+-------------------+\n",
      "|  count|             6990280|             6990280|             6990280|           6990280|               6990280|            6990280|\n",
      "|   mean|                NULL|                NULL|                NULL|  3.74858374771826|                  NULL|               NULL|\n",
      "| stddev|                NULL|                NULL|                NULL|1.4787045052556855|                  NULL|               NULL|\n",
      "|    min|---4VcQZzy_vIIifU...|---1lKK3aKOuomHnw...|---kPU91CF4Lq2-Wl...|               1.0|  !\\nMilk Bar is po...|2005-02-16 03:23:22|\n",
      "|    max|zzzz1ADBqBEVyfX4l...|zzzUFM4HFe0SFG0bP...|zzyx5x0Z7xXWWvWnZ...|               5.0|＼(^o^)／\\nThey hav...|2022-01-19 19:48:45|\n",
      "+-------+--------------------+--------------------+--------------------+------------------+----------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# cantidad de registos\n",
    "df_filter_review.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4594836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:=========================================>             (30 + 10) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+-----------------+-----------+----------+----------+\n",
      "|review_id_nulos|user_id_nulos|business_id_nulos|stars_nulos|text_nulos|date_nulos|\n",
      "+---------------+-------------+-----------------+-----------+----------+----------+\n",
      "|              0|            0|                0|          0|         0|         0|\n",
      "+---------------+-------------+-----------------+-----------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# nulos\n",
    "df_filter_review.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c + '_nulos') \n",
    "    for c in df_filter_review.columns\n",
    "]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a093e7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:=========================================>             (30 + 10) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|stars|  count|\n",
      "+-----+-------+\n",
      "|  1.0|1069561|\n",
      "|  2.0| 544240|\n",
      "|  3.0| 691934|\n",
      "|  4.0|1452918|\n",
      "|  5.0|3231627|\n",
      "+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# únicos de stars\n",
    "df_filter_review.groupBy(\"stars\").count().orderBy(\"stars\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62e30c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filter_review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7e7b2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -> timestamp\n",
    "df_filter_review = df_filter_review.withColumn(\"date\", F.to_timestamp(\"date\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "df_filter_review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5c4a6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=========================================>             (30 + 10) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+\n",
      "| año|mes|count|\n",
      "+----+---+-----+\n",
      "|2010| 11|    2|\n",
      "|2010| 12|    4|\n",
      "|2011|  2|    1|\n",
      "|2011|  3|    2|\n",
      "|2011|  4|    2|\n",
      "|2011|  5|    3|\n",
      "|2011|  6|    3|\n",
      "|2011|  7|    9|\n",
      "|2011|  8|    2|\n",
      "|2011| 12|    2|\n",
      "|2012|  1|    3|\n",
      "|2012|  2|    3|\n",
      "|2012|  3|    2|\n",
      "|2012|  4|    4|\n",
      "|2012|  5|    1|\n",
      "|2012|  8|    4|\n",
      "|2012|  9|    3|\n",
      "|2012| 10|    2|\n",
      "|2012| 11|    4|\n",
      "|2012| 12|    4|\n",
      "+----+---+-----+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# vemos la serie temporal por un negocio\n",
    "df_negocio = df_filter_review.filter(df_filter_review.business_id == '7ATYjTIgM3jUlt4UM3IypQ')\n",
    "df_negocio_serie_temporal = df_negocio.groupBy(F.year(\"date\").alias(\"año\"), F.month(\"date\").alias(\"mes\")) \\\n",
    "    .count() \\\n",
    "    .orderBy(\"año\", \"mes\")\n",
    "df_negocio_serie_temporal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "824d1577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pasamos a pandas para graficar \n",
    "df_negocio_serie_temporal_pd = df_negocio_serie_temporal.toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_negocio_serie_temporal_pd['año'].astype(str) + '-' + df_negocio_serie_temporal_pd['mes'].astype(str),\n",
    "         df_negocio_serie_temporal_pd['count'], marker='o', linestyle='-', color='b')\n",
    "plt.title('Reseñas por año-mes')\n",
    "plt.xlabel('Año-mes')\n",
    "plt.ylabel('Número de reseñas')\n",
    "plt.xticks(rotation=90) # para ver bien los labels\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71e725",
   "metadata": {},
   "source": [
    "Verificamos y tenemos los registros completos por cada variable, stars se maneja en un rango de 1-5, formateamos date y usando id de negocios de prueba vemos su series temporal de reseñas por mes-año"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655e2ed",
   "metadata": {},
   "source": [
    "## User"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1276ccc",
   "metadata": {},
   "source": [
    "- user_id\n",
    "- review_count\n",
    "- average_stars\n",
    "- yelping_since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "951e417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_user = df_user.select(\"user_id\", \"review_count\", \"average_stars\", \"yelping_since\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41147609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:=================================================>      (23 + 3) / 26]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+------------------+-------------------+\n",
      "|summary|             user_id|      review_count|     average_stars|      yelping_since|\n",
      "+-------+--------------------+------------------+------------------+-------------------+\n",
      "|  count|             1987897|           1987897|           1987897|            1987897|\n",
      "|   mean|                NULL|23.394409267683386|  3.63049415035087|               NULL|\n",
      "| stddev|                NULL| 82.56699161797889|1.1833369995975145|               NULL|\n",
      "|    min|---1lKK3aKOuomHnw...|                 0|               1.0|2004-10-12 08:46:11|\n",
      "|    max|zzzUFM4HFe0SFG0bP...|             17473|               5.0|2022-01-19 17:15:47|\n",
      "+-------+--------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_filter_user.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b50cd33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:===============================================>        (22 + 4) / 26]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+-------------------+-------------------+\n",
      "|user_id_nulos|review_count_nulos|average_stars_nulos|yelping_since_nulos|\n",
      "+-------------+------------------+-------------------+-------------------+\n",
      "|            0|                 0|                  0|                  0|\n",
      "+-------------+------------------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_filter_user.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c + '_nulos') \n",
    "    for c in df_filter_user.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd4286e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:=============================================>          (21 + 5) / 26]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|average_stars| count|\n",
      "+-------------+------+\n",
      "|          1.0|165899|\n",
      "|         1.01|     1|\n",
      "|         1.02|     3|\n",
      "|         1.03|     5|\n",
      "|         1.04|    15|\n",
      "|         1.05|    17|\n",
      "|         1.06|    25|\n",
      "|         1.07|    31|\n",
      "|         1.08|    55|\n",
      "|         1.09|    48|\n",
      "|          1.1|    71|\n",
      "|         1.11|   108|\n",
      "|         1.12|    13|\n",
      "|         1.13|   152|\n",
      "|         1.14|   271|\n",
      "|         1.15|    28|\n",
      "|         1.16|    15|\n",
      "|         1.17|   464|\n",
      "|         1.18|    54|\n",
      "|         1.19|    31|\n",
      "+-------------+------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_filter_user.groupBy(\"average_stars\").count().orderBy(\"average_stars\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d18e16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- yelping_since: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filter_user.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2ae7750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- yelping_since: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cambiamos el tipo de dato de yelping_since\n",
    "df_filter_user = df_filter_user.withColumn(\"yelping_since\", F.to_timestamp(\"yelping_since\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "df_filter_user.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4add34af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# para graficar\n",
    "df_reviews_pd = df_filter_user.toPandas()\n",
    "\n",
    "# promedio de estrellas por usuario\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_reviews_pd['average_stars'], bins=20, color='lightgreen', edgecolor='black')\n",
    "plt.title('Distribución promedio de estrellas por Usuario')\n",
    "plt.xlabel('Promedio de Estrellas')\n",
    "plt.ylabel('Cantidad de Usuarios')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41db8c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# antigüedad de los usuarios\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_reviews_pd['yelping_since'], bins=30, color='orange', edgecolor='black')\n",
    "plt.title('Distribución de Antigüedad de los Usuarios en Yelp')\n",
    "plt.xlabel('Antigüedad en Años')\n",
    "plt.ylabel('Cantidad de Usuarios')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b761d",
   "metadata": {},
   "source": [
    "## Business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef8d8b0",
   "metadata": {},
   "source": [
    "- business_id\n",
    "- name\n",
    "- city\n",
    "- state\n",
    "- latitude\n",
    "- longitude\n",
    "- categories\n",
    "- stars\n",
    "- review_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c42a0b",
   "metadata": {},
   "source": [
    "stars: Promedio de las calificaciones de todas las reseñas de un negocio específico (puntuación promedio de 1 a 5 estrellas de todos los usuarios que han dejado reseñas para ese negocio).\n",
    "\n",
    "será renombrada al final a reviews_stars para evitar conflicto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3c756ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_business = df_business.select(\"business_id\", \"name\", \"city\", \"state\", \"latitude\", \"longitude\", \"categories\", \"stars\", \"review_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "003615d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----------+------+-----------------+------------------+--------------------+------------------+-----------------+\n",
      "|summary|         business_id|                name|       city| state|         latitude|         longitude|          categories|             stars|     review_count|\n",
      "+-------+--------------------+--------------------+-----------+------+-----------------+------------------+--------------------+------------------+-----------------+\n",
      "|  count|              150346|              150346|     150346|150346|           150346|            150346|              150243|            150346|           150346|\n",
      "|   mean|                NULL|              1252.4|       NULL|  NULL|36.67115006414571|-89.35733948971429|                NULL|3.5967235576603303|44.86656113232144|\n",
      "| stddev|                NULL|   811.1275005954503|       NULL|  NULL|5.872758917014048| 14.91850167993062|                NULL|0.9744207509201364|121.1201357011708|\n",
      "|    min|---kPU91CF4Lq2-Wl...|        Grow Academy|AB Edmonton|    AB|        27.555127|       -120.095137|3D Printing, Loca...|               1.0|                5|\n",
      "|    max|zzyx5x0Z7xXWWvWnZ...|​​Transformationa...|    ​Lithia|   XMS|       53.6791969|    -73.2004570502|Zoos, Tours, Arts...|               5.0|             7568|\n",
      "+-------+--------------------+--------------------+-----------+------+-----------------+------------------+--------------------+------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_filter_business.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8999312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+----------+-----------+--------------+---------------+----------------+-----------+------------------+\n",
      "|business_id_nulos|name_nulos|city_nulos|state_nulos|latitude_nulos|longitude_nulos|categories_nulos|stars_nulos|review_count_nulos|\n",
      "+-----------------+----------+----------+-----------+--------------+---------------+----------------+-----------+------------------+\n",
      "|                0|         0|         0|          0|             0|              0|             103|          0|                 0|\n",
      "+-----------------+----------+----------+-----------+--------------+---------------+----------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filter_business.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c + '_nulos') \n",
    "    for c in df_filter_business.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01e89d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+-----+----------+------------+----------+-----+------------+\n",
      "|         business_id|                name|            city|state|  latitude|   longitude|categories|stars|review_count|\n",
      "+--------------------+--------------------+----------------+-----+----------+------------+----------+-----+------------+\n",
      "|SMYXOLPyM95JvZ-oq...|A A Berlin Glass ...|          Berlin|   NJ|39.8004163| -74.9371806|      NULL|  3.0|           5|\n",
      "|9ryVeDaaR-le3kiSa...|Pauline African H...|       Saint Ann|   MO|38.7260321| -90.3793227|      NULL|  1.0|           5|\n",
      "|xT3J-SP5g49g2FjQf...|      Luxury Perfume|            Reno|   NV|39.4756225|-119.7833497|      NULL|  2.0|           5|\n",
      "|_obl2-rphXvtzP3y_...|Certegy Payment S...|Saint Petersburg|   FL|27.8774633| -82.6535459|      NULL|  1.0|           7|\n",
      "|mKxCNYEoKt6d_1rXm...|          Green Envy|   Saint Charles|   MO| 38.826533| -90.4722239|      NULL|  1.5|           5|\n",
      "|9QoKKDZB_YuDeS5Tx...|   Our 365 Portraits|     Saint Louis|   MO|38.5614292| -90.3718048|      NULL|  1.0|          10|\n",
      "|lxaSo0sBK36BNDRL6...|Parklane Manageme...|           Boise|   ID|43.6205297|-116.2000815|      NULL|  1.0|           5|\n",
      "|ZERQMWb1PFzCfbfkn...|   Pilot Air Freight|           Media|   PA|39.9179763| -75.4418924|      NULL|  1.5|           8|\n",
      "|cs7i8-NtrT2P4dMYa...|          Direct USA|           Tampa|   FL|28.0078574| -82.5491156|      NULL|  1.0|           5|\n",
      "|tfQEd3kakCQdbjfdp...|Nicholson's Colle...|         Marrero|   LA|29.8757377| -90.1068608|      NULL|  2.5|           5|\n",
      "|NpQowTAUYGeylRCAs...|      Skaters Choice|           Tampa|   FL|27.9931964| -82.4833777|      NULL|  4.5|           8|\n",
      "|7cEbbI3wjuGSsJUIG...|                Qmar|  Tarpon Springs|   FL|28.1503407| -82.7564411|      NULL|  5.0|           7|\n",
      "|6aVfpb46kY1FN7nFc...|Smart Cents Cleaners|          Berwyn|   PA|40.0477679| -75.4365588|      NULL|  1.0|           7|\n",
      "|_LoMSJiz4dLYnqwRN...|Sure Payroll Service|          Primos|   PA|39.9303332| -75.3050139|      NULL|  1.0|           8|\n",
      "|Dngea1LMy4JhJiC5m...| Positive Promotions|          Newark|   DE|39.6652322| -75.6618254|      NULL|  1.0|          10|\n",
      "|2M_l_vsJx2T_Ihu2X...|Higginbottom's He...|          Kenner|   LA|30.0298704| -90.2305673|      NULL|  2.0|           7|\n",
      "|Ap9LaMbl1hJX0c7q3...|Adriatic Insuranc...|        Metairie|   LA|30.0127115| -90.1539606|      NULL|  1.0|           6|\n",
      "|qnJ5tZf2eHrvNZXN5...|Cope Behavioral S...|          Tucson|   AZ|32.1310473|-110.9970941|      NULL|  2.5|           5|\n",
      "|aya_GU5A7-cB3-G3I...|Dollar General Store|        Metairie|   LA|30.0015038| -90.1615687|      NULL|  1.5|           5|\n",
      "|S1OERFoPAqaDqr5_d...| Keter North America|          Carmel|   IN|39.9541132| -86.1539523|      NULL|  2.5|           7|\n",
      "+--------------------+--------------------+----------------+-----+----------+------------+----------+-----+------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# revisamos nulos\n",
    "df_filter_business.filter(F.col(\"categories\").isNull()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "291ed3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----+-----+--------+---------+----------+-----+------------+\n",
      "|business_id|name|city|state|latitude|longitude|categories|stars|review_count|\n",
      "+-----------+----+----+-----+--------+---------+----------+-----+------------+\n",
      "+-----------+----+----+-----+--------+---------+----------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# no sabemos la razón exacta de los nulos y debido a que representa el 0.0685% del total, lo eliminamos\n",
    "\n",
    "df_filter_business = df_filter_business.filter(F.col(\"categories\").isNotNull())\n",
    "\n",
    "# verificamos\n",
    "df_filter_business.filter(F.col(\"categories\").isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e418f1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+----------+-----------+--------------+---------------+----------------+-----------+------------------+\n",
      "|business_id_nulos|name_nulos|city_nulos|state_nulos|latitude_nulos|longitude_nulos|categories_nulos|stars_nulos|review_count_nulos|\n",
      "+-----------------+----------+----------+-----------+--------------+---------------+----------------+-----------+------------------+\n",
      "|                0|         0|         0|          0|             0|              0|               0|          0|                 0|\n",
      "+-----------------+----------+----------+-----------+--------------+---------------+----------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filter_business.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c + '_nulos') \n",
    "    for c in df_filter_business.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d49f893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|stars|count|\n",
      "+-----+-----+\n",
      "|  1.0| 1948|\n",
      "|  1.5| 4918|\n",
      "|  2.0| 9515|\n",
      "|  2.5|14307|\n",
      "|  3.0|18448|\n",
      "|  3.5|26512|\n",
      "|  4.0|31120|\n",
      "|  4.5|27174|\n",
      "|  5.0|16301|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# distribución de stars\n",
    "df_filter_business.groupBy(\"stars\").count().orderBy(\"stars\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f59174d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_business_pd = df_filter_business.toPandas()\n",
    "# relación entre review_count y stars para ver si hay alguna correlación\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_business_pd['stars'], df_business_pd['review_count'], color='purple', alpha=0.5)\n",
    "plt.title('Relación entre Número de Reseñas y Estrellas del Negocio')\n",
    "plt.xlabel('Promedio estrellas')\n",
    "plt.ylabel('Reseñas')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e81e43",
   "metadata": {},
   "source": [
    "> Verificamos que en los 3 principales datasets, pasaron por un proceso de EDA y actualmente están listas para usar e integrarlas en un dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca63963",
   "metadata": {},
   "source": [
    "# Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bd4564",
   "metadata": {},
   "source": [
    "Usaremos inner join porque queremos crear un dataset donde cada reseña, el usuario que la escribió y el negocio al que pertenece, estén todos conectados y existan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ff3c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# antes, renombraremos stars (review, business) para evitar conflicto\n",
    "df_filter_review = df_filter_review.withColumnRenamed(\"stars\", \"review_stars\")\n",
    "df_filter_business = df_filter_business.withColumnRenamed(\"stars\", \"business_stars\")\n",
    "\n",
    "# lo mismo hacemos con review_count (user, business)\n",
    "df_filter_business = df_filter_business.withColumnRenamed(\"review_count\", \"business_review_count\")\n",
    "df_filter_user = df_filter_user.withColumnRenamed(\"review_count\", \"user_review_count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea6da76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------------------+----------------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------------------------------+-----------+-----+-------------+--------------+---------------------------------------------------------------------------------+--------------+---------------------+-----------------+-------------+-------------------+\n",
      "|user_id               |business_id           |review_id             |review_stars|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |date               |name                             |city       |state|latitude     |longitude     |categories                                                                       |business_stars|business_review_count|user_review_count|average_stars|yelping_since      |\n",
      "+----------------------+----------------------+----------------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------------------------------+-----------+-----+-------------+--------------+---------------------------------------------------------------------------------+--------------+---------------------+-----------------+-------------+-------------------+\n",
      "|---UgP94gokyCDuB5zUssA|mnq8JNUjIBwUoLBk-b2V9g|Y-xvJ7cN2Sul8Ub-qypLSg|4.0         |I come here at least twice a week and to Start the emlployees are so nice and courteous, they know my order and always cater to my every need. I really do enjoy there Smoothies and Bowls with fruit and yogurt as seen on the pic I posted..DELICIOUS and will be back tomorrow if not Friday for more.. Thanks again and I definitely recommend to anyone who hasn't tried it!                                                                                                                                                                                              |2014-11-19 15:48:24|Jamba                            |New Orleans|LA   |29.950181    |-90.074232    |Juice Bars & Smoothies, Sandwiches, Restaurants, Food                            |4.0           |67                   |16               |3.44         |2014-11-02 14:53:16|\n",
      "|---UgP94gokyCDuB5zUssA|LY6hHivaMJIPJNv_3oBIPQ|bk8w-9nDgwo6BKc_EHaLbw|1.0         |So I'd like to say that I wasn't impressed with the food at all. The concept is great and the idea also but, food overall is very overrated. I'm not her to talk trash but, I can definitely do better then why I ate the other day when I came to pick up my order. The best thing was the BLACKBERRY LEMONADE. The fried cauliflower was too greasy and oily and the Burrito was too watery. It can be made better beyond what it was. This is just helpful criticism and by no means trying to not make anyone not go there.                                                |2020-05-12 01:45:33|Vegan Wit A Twist                |New Orleans|LA   |29.9499993   |-90.0748774   |Vegan, Restaurants                                                               |4.5           |125                  |16               |3.44         |2014-11-02 14:53:16|\n",
      "|---UgP94gokyCDuB5zUssA|NAMen7YzwlYDs_5ECMnuYQ|1NBv0_p82wbgk8uZ_FmNnA|5.0         |From the moment we walked in till the moment we left, myself and my wife were beyond pleased with the quality and friendly service and outstanding food. I definitely suggest this place to anyone looking for good bbq/food/service..we'll definitely be coming back soon                                                                                                                                                                                                                                                                                                     |2019-06-29 20:59:59|Truck Farm Tavern                |Saint Rose |LA   |29.9421566008|-90.3226030545|Food, Comfort Food, Nightlife, Restaurants, Bars, Pubs, Southern                 |4.0           |137                  |16               |3.44         |2014-11-02 14:53:16|\n",
      "|---UgP94gokyCDuB5zUssA|Sel6lYActdRhEPQ4WXycxA|aIez3IZipxBQxGX-Rd7HSg|4.0         |I work downtown and I seen this truck this morning and it caught my attention. I kept seeing people with TO-GO boxes with food and they were saying nothing but, great things about the food on this truck. Myself and co-worker decided to go and let me just say \"WOW\"....we definitely got our $'s worth with the plates we got. I had the \"PHILLY CAJUN\"....absolutely delicious sandwich and I destroyed it in a matter of minutes . I'll definitely recommend them to anyone that sees them or goes to their truck..thank y'all again for great/delicious food..GOD BLESS|2021-09-17 17:36:13|Kenny's Cajun & Creole Food Truck|Harvey     |LA   |29.8699332   |-90.0653341   |Cajun/Creole, Food Trucks, Food, Restaurants, Event Planning & Services, Caterers|3.0           |8                    |16               |3.44         |2014-11-02 14:53:16|\n",
      "|---UgP94gokyCDuB5zUssA|hKr-RKMVpj3gRkSWcjg3Zw|gtaE5Mu317tS4QHa0J0hfQ|3.0         |So I was in the mood for some Tacos and not Taco bell but real Mexican Tacos. So I came here and got friendly service, my order was to go so my wait wasn't long either. Restaurant is TV friendly, Menu shows you what you'll be eating and how it looks exactly which I think is a good idea especially when their are so many Mexican restaurants out there. That made it very unique to me. Food overall was great, I love Tacos de Lengua or Tongue Tacos and they packed then nicely for the $. I'll definitely go back when I get urge for Tacos or Mexican in general! |2014-11-10 02:49:07|Antojitos El Arriero             |Kenner     |LA   |30.004618    |-90.241026    |American (New), Restaurants, Mexican                                             |3.0           |14                   |16               |3.44         |2014-11-02 14:53:16|\n",
      "+----------------------+----------------------+----------------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+---------------------------------+-----------+-----+-------------+--------------+---------------------------------------------------------------------------------+--------------+---------------------+-----------------+-------------+-------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# reseñas con negocios\n",
    "df_reseñas_negocios = df_filter_review.join(df_filter_business, on=\"business_id\", how=\"inner\")\n",
    "\n",
    "# con usuarios\n",
    "df_completo = df_reseñas_negocios.join(df_filter_user, on=\"user_id\", how=\"inner\")\n",
    "\n",
    "# df final\n",
    "df_completo.show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "734f15a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 170:============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DF en memoria (Spark): 7.06 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/25 14:35:34 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 186561 ms exceeds timeout 120000 ms\n",
      "25/06/25 14:35:34 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/06/25 14:35:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:35:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:41:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:41:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:48:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:48:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:50:33 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:50:33 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:52:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:52:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:52:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:52:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:55:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:55:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:56:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:56:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:56:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:56:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:56:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:56:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:56:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:56:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:57:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:58:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 14:59:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:00:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:01:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:01:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:01:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:01:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:01:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:01:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:01:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/06/25 15:01:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/06/25 15:01:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:01:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:01:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:01:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:02:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:03:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:04:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:05:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:05:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.20:53879\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/25 15:05:05 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "# convertimos el df a RDD para contar el tamaño\n",
    "df_size_in_bytes = df_completo.rdd.map(lambda x: len(str(x))).sum()\n",
    "df_size_gb = df_size_in_bytes / (1024 ** 3)\n",
    "\n",
    "print(f\"Tamaño DF en memoria (Spark): {df_size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86c7325a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- review_stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- business_stars: double (nullable = true)\n",
      " |-- business_review_count: long (nullable = true)\n",
      " |-- user_review_count: long (nullable = true)\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- yelping_since: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_completo.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b15d2431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 94:==================================>                      (6 + 4) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+---------------+------------------+----------+----------+----------+----------+-----------+--------------+---------------+----------------+--------------------+---------------------------+-----------------------+-------------------+-------------------+\n",
      "|user_id_nulos|business_id_nulos|review_id_nulos|review_stars_nulos|text_nulos|date_nulos|name_nulos|city_nulos|state_nulos|latitude_nulos|longitude_nulos|categories_nulos|business_stars_nulos|business_review_count_nulos|user_review_count_nulos|average_stars_nulos|yelping_since_nulos|\n",
      "+-------------+-----------------+---------------+------------------+----------+----------+----------+----------+-----------+--------------+---------------+----------------+--------------------+---------------------------+-----------------------+-------------------+-------------------+\n",
      "|            0|                0|              0|                 0|         0|         0|         0|         0|          0|             0|              0|               0|                   0|                          0|                      0|                  0|                  0|\n",
      "+-------------+-----------------+---------------+------------------+----------+----------+----------+----------+-----------+--------------+---------------+----------------+--------------------+---------------------------+-----------------------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_completo.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c + '_nulos') \n",
    "    for c in df_completo.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "750c666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 111:============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+------------------+----------------------+--------------------+-----------+-------+------------------+------------------+--------------------+------------------+---------------------+------------------+------------------+\n",
      "|summary|             user_id|         business_id|           review_id|      review_stars|                  text|                name|       city|  state|          latitude|         longitude|          categories|    business_stars|business_review_count| user_review_count|     average_stars|\n",
      "+-------+--------------------+--------------------+--------------------+------------------+----------------------+--------------------+-----------+-------+------------------+------------------+--------------------+------------------+---------------------+------------------+------------------+\n",
      "|  count|             6989558|             6989558|             6989558|           6989558|               6989558|             6989558|    6989558|6989558|           6989558|           6989558|             6989558|           6989558|              6989558|           6989558|           6989558|\n",
      "|   mean|                NULL|                NULL|                NULL| 3.748740192155212|                  NULL|   1289.232590529248|       NULL|   NULL|35.948369754163856| -89.7284778795858|                NULL|3.7514827833176287|    369.2084141801241|123.84012651443769| 3.746568348097556|\n",
      "| stddev|                NULL|                NULL|                NULL|1.4785964756580827|                  NULL|   701.2574322404712|       NULL|   NULL| 5.347203197628688|14.887347492743851|                NULL|0.7536939698790127|    736.1080024360618|363.44580990176934|0.8617268537604789|\n",
      "|    min|---1lKK3aKOuomHnw...|---kPU91CF4Lq2-Wl...|---4VcQZzy_vIIifU...|               1.0|  !\\nMilk Bar is po...|        Grow Academy|AB Edmonton|     AB|         27.555127|       -120.095137|3D Printing, Loca...|               1.0|                    5|                 0|               1.0|\n",
      "|    max|zzzUFM4HFe0SFG0bP...|zzyx5x0Z7xXWWvWnZ...|zzzz1ADBqBEVyfX4l...|               5.0|＼(^o^)／\\nThey hav...|​​Transformationa...|    ​Lithia|    XMS|        53.6791969|    -73.2004570502|Zoos, Tours, Arts...|               5.0|                 7568|             17473|               5.0|\n",
      "+-------+--------------------+--------------------+--------------------+------------------+----------------------+--------------------+-----------+-------+------------------+------------------+--------------------+------------------+---------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_completo.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b5a33",
   "metadata": {},
   "source": [
    "Usaremos polars para graficar la matriz de correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc3511b",
   "metadata": {},
   "source": [
    "Esto es a modo experimento donde el siguiente código producirá error porque estamos realizando una operación que requiere más memoria de la que tenemos disponible. \n",
    "En nuesto caso ocurrió por intentar mover grandes cantidades de datos entre spark y pandas ´df_completo.toPandas()´.\n",
    "Aquí pandas cargo todo a memoria y por ser un caso de big data, causo problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4aa22961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport polars as pl\\nimport seaborn as sns\\n\\ndf_polars = pl.from_pandas(df_completo.toPandas())\\n\\n# solo numéricas\\nnumerical_columns = [col for col, dtype in zip(df_polars.columns, df_polars.dtypes) if dtype in (\\'int64\\', \\'float64\\')]\\n\\ndf_numeric = df_polars.select(numerical_columns)\\n\\ncorr_matrix = df_numeric.corr()\\ncorr_matrix_df = corr_matrix.to_pandas()\\n\\n# heatmap\\nplt.figure(figsize=(12, 8))\\nsns.heatmap(corr_matrix_df, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\\nplt.title(\"Matriz de Correlación con Polars\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "\n",
    "df_polars = pl.from_pandas(df_completo.toPandas())\n",
    "\n",
    "# solo numéricas\n",
    "numerical_columns = [col for col, dtype in zip(df_polars.columns, df_polars.dtypes) if dtype in ('int64', 'float64')]\n",
    "\n",
    "df_numeric = df_polars.select(numerical_columns)\n",
    "\n",
    "corr_matrix = df_numeric.corr()\n",
    "corr_matrix_df = corr_matrix.to_pandas()\n",
    "\n",
    "# heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix_df, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Matriz de Correlación con Polars\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea838534",
   "metadata": {},
   "source": [
    "Lo interesante aquí es que este error, de alguna forma afecto la sesión actual de spark.\n",
    "Algunas de las operaciones que ejecutó pandas o polars que están relacionadas con el manejo de memoria, pudo haber afectado la estabilidad de la sesión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ae5d3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/25 11:24:09 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filtro solo numéricas\n",
    "numerical_columns = [c for c, dtype in df_completo.dtypes if dtype in ('int', 'double')]\n",
    "\n",
    "# spark requiere tenerlas en un vector\n",
    "assembler = VectorAssembler(inputCols=numerical_columns, outputCol=\"features\")\n",
    "df_vector = assembler.transform(df_completo)\n",
    "\n",
    "correlation_matrix = Correlation.corr(df_vector, \"features\", \"pearson\").head()\n",
    "\n",
    "# pasamos a array para poder visuaizar\n",
    "corr_matrix = correlation_matrix[0].toArray()\n",
    "corr_matrix_df = pd.DataFrame(corr_matrix, columns=numerical_columns, index=numerical_columns)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix_df, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Matriz de Correlación con Spark\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e30a3e",
   "metadata": {},
   "source": [
    "- Vemos una correlación moderada entre las reseñas de los usuarios y las estrellas promedio del negocio, lo que podría ser indicio que los negocios con buenas calificaciones tienden a recibir buenas reseñas\n",
    "\n",
    "- Además la relación entre las estrellas de reseña y el promedio de estrellas del usuario también muestra una correlación positiva, lo que indicaría que los usuarios dan calificaciones similares a sus reseñas previas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56405a03",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ac2f1",
   "metadata": {},
   "source": [
    "Guardamos en formato parquet para considerar aprovechar mantener el esquema actual, además está optimizado para spark y compatible HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ea72e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_parquet = \"../data/silver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccb84799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ajustamos a 10 particiones porque de lo contrario excedemos el 95% de memoria disponible\n",
    "df_completo = df_completo.repartition(10)\n",
    "# divide el df en 10 particiones de manera equitativa, es decir, lo hicimos sin particionamiento explícito\n",
    "\n",
    "df_completo.write.parquet(path_parquet, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "675ad82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------------+--------------------+-------------------+--------------------+--------------+-----+------------+-----------+--------------------+--------------+---------------------+-----------------+-------------+-------------------+\n",
      "|             user_id|         business_id|           review_id|review_stars|                text|               date|                name|          city|state|    latitude|  longitude|          categories|business_stars|business_review_count|user_review_count|average_stars|      yelping_since|\n",
      "+--------------------+--------------------+--------------------+------------+--------------------+-------------------+--------------------+--------------+-----+------------+-----------+--------------------+--------------+---------------------+-----------------+-------------+-------------------+\n",
      "|V_j-mYsa8Xrn_KEw-...|8pqdJjefYq-a9IBSJ...|qwFjyODKMeBR84Lyh...|         4.0|Wish it wasn't so...|2016-03-01 04:36:36|       The Dandelion|  Philadelphia|   PA|   39.951004| -75.170636|British, Restaura...|           4.0|                 2497|               25|         2.72|2011-02-03 03:00:12|\n",
      "|n5akoFanouUGEGl3I...|RswmJ6uEY7gRwws7a...|dJySz86uyjbr8aaxb...|         5.0|Outstanding servi...|2019-11-26 20:10:37|Grande Style Pet ...|         Tampa|   FL|  28.0921891| -82.501301|Pet Groomers, Pet...|           4.5|                   23|               16|         4.37|2015-06-06 18:20:46|\n",
      "|pZyDxXKB6jOiZMCJW...|ZMx3hds9eH24geGku...|HvS3IsGEg8GYhnjUx...|         1.0|Don't eat here. I...|2020-11-24 03:27:51|        Bangkok Thai|   New Orleans|   LA|  29.9424398|-90.1342512|   Restaurants, Thai|           3.5|                  131|               11|          4.0|2015-10-18 00:26:37|\n",
      "|FwayRcJ1yossTI9Ea...|_4LtVmrCdz40l1Dnp...|sfOzOd06tjeJ6CB2p...|         1.0|Unfortunate, spen...|2020-12-06 00:44:31|            Tin Roof|     Nashville|   TN|  36.1532885|-86.7900562|Beer, Wine & Spir...|           3.0|                  215|                1|          1.0|2019-09-08 17:43:22|\n",
      "|qmhIomEgX7Eol3QmI...|X9e-lTfOeY0z6C-VA...|MC38l8XJscvC9Zw4K...|         5.0|Tender, delicious...|2014-07-14 22:18:44|Dickey's Barbecue...|St. Petersburg|   FL|27.790827399| -82.725962|Restaurants, Chic...|           4.0|                  121|               25|         4.37|2010-12-19 00:02:53|\n",
      "+--------------------+--------------------+--------------------+------------+--------------------+-------------------+--------------------+--------------+-----+------------+-----------+--------------------+--------------+---------------------+-----------------+-------------+-------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# leer\n",
    "df_completo_parquet = spark.read.parquet(path_parquet)\n",
    "\n",
    "df_completo_parquet.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd23ed",
   "metadata": {},
   "source": [
    "Veremos que en la capa silver (carpeta silver) se crearon las particiones (.part-00...) en formato parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96777ff6",
   "metadata": {},
   "source": [
    "Para una próxima lectura, spark de forma automática maneja las particiones internamente y no es necesario recorrerlas manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ecfd617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño archivo Parquet: 3.27 GB\n"
     ]
    }
   ],
   "source": [
    "path_parquet = \"../data/silver\"\n",
    "\n",
    "# función recursiva para obtener el tamaño de los archivos en subdirectorios\n",
    "def get_total_size(path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for file in filenames:\n",
    "            total_size += os.path.getsize(os.path.join(dirpath, file))\n",
    "    return total_size\n",
    "\n",
    "total_size = get_total_size(path_parquet)\n",
    "total_size_gb = total_size / (1024 ** 3)\n",
    "\n",
    "print(f\"Tamaño archivo Parquet: {total_size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buena práctica 🤓\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yelp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
