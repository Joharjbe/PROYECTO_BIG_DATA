### ‚ñ™ Introducci√≥n y justificaci√≥n del problema a resolver

El proyecto nace de la necesidad de conocer buenos lugares como restaurantes, caf√©s y dem√°s establecimientos.  
Actualmente, para Lima (Per√∫), la fuente m√°s cercana es **Google Maps** que, si bien es √∫til, suele mostrar informaci√≥n escasa, con pocas rese√±as y datos desactualizados del local, entre otras dificultades.

Para descubrir alternativas, recordamos el **episodio 4 ‚Äì temporada 19 de _South Park_**, donde uno de los protagonistas se vuelve cr√≠tico de Yelp y se muestra c√≥mo esta plataforma adquiere gran relevancia en la ficci√≥n. <!-- link disimulado -->  
*[Ver episodio en South Park Latinoam√©rica](https://www.southpark.lat/episodios/en0srq/south-park-no-resenas-yelp-temporada-19-ep-4)*

Yelp es un sitio web y app donde los usuarios escriben y leen rese√±as y valoraciones de negocios locales (restaurantes, talleres, dentistas, etc.), ayudando a encontrar y contactar establecimientos cercanos. Fue fundada en **octubre de 2004** y hoy est√° presente en Am√©rica del Norte, Europa, Ocean√≠a, **Am√©rica del Sur (Brasil)** y Asia.

Nos pareci√≥ fascinante la magnitud de la empresa y la idea detr√°s de ella. Entonces nos preguntamos c√≥mo, con esa informaci√≥n, un negocio ‚Äîviejo o nuevo‚Äî podr√≠a beneficiarse. Por ejemplo: con tantas rese√±as disponibles, un sistema que las lea autom√°ticamente (sin intervenci√≥n humana) y las clasifique seg√∫n si las personas salieron satisfechas o insatisfechas del local permitir√≠a obtener _insights_ valiosos y oportunidades de mejora.

Con ello, el negocio podr√≠a:

- Medir en tiempo real el pulso de la experiencia del cliente.  
- Detectar problemas antes de que escalen.  
- Comprobar si las mejoras se reflejan en un aumento de rese√±as positivas.  

Todo esto **sin** tener que leer miles de comentarios uno por uno.

¬øInteresante, no?


### ‚ñ™ Descripci√≥n del dataset, origen y tama√±o de data

Para este proyecto investigamos distintas fuentes de origen, entre ellas el  
*[Yelp Open Dataset](https://business.yelp.com/data/resources/open-dataset/)* y, finalmente, nos quedamos con un dataset extra√≠do de *[Kaggle ‚Äì Yelp Dataset](https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset/data?select=yelp_academic_dataset_user.json)*.

Se trata de una **muestra p√∫blica** de la informaci√≥n que Yelp guarda sobre negocios, rese√±as y usuarios. Yelp la public√≥ para su ‚ÄúDataset Challenge‚Äù, un concurso que anima a estudiantes a investigar los datos y compartir lo que descubran. La √∫ltima versi√≥n abarca empresas de **ocho grandes ciudades** de EE. UU. y Canad√°.

El conjunto contiene **5 archivos JSON** que, en total, suman **9.29 GB** de datos:

- **Rese√±as completas**: `yelp_academic_dataset_review.json` ‚Äî **5.34 GB**  
- **Ficha de cada negocio**: `yelp_academic_dataset_business.json` ‚Äî **118.86 MB**  
- **Perfil de cada usuario**: `yelp_academic_dataset_user.json` ‚Äî **3.36 GB**  
- **Historial de visitas por negocio**: `yelp_academic_dataset_checkin.json` ‚Äî **286.96 MB**  
- **Consejos breves (‚Äútips‚Äù)**: `yelp_academic_dataset_tip.json` ‚Äî **180.6 MB**

Creamos el siguiente diccionario de datos

#### **Archivo: `yelp_academic_dataset_business.json`**

| **Columna**   | **Tipo** | **Descripci√≥n** |
|---------------|----------|-----------------|
| `address`     | string   | Direcci√≥n del negocio. |
| `attributes`  | struct   | Estructura con varios atributos del negocio, como la aceptaci√≥n de tarjetas de cr√©dito, estacionamiento, etc. |
| `business_id` | string   | Identificador √∫nico del negocio. |
| `categories`  | string   | Categor√≠as asociadas con el negocio (por ejemplo, Restaurantes, Tiendas, etc.). |
| `city`        | string   | Ciudad donde se encuentra el negocio. |
| `hours`       | struct   | Horarios de apertura y cierre para cada d√≠a de la semana. |
| `is_open`     | long     | Indica si el negocio est√° abierto (1) o cerrado (0). |
| `latitude`    | double   | Latitud geogr√°fica del negocio. |
| `longitude`   | double   | Longitud geogr√°fica del negocio. |
| `name`        | string   | Nombre del negocio. |
| `postal_code` | string   | C√≥digo postal del negocio. |
| `review_count`| long     | N√∫mero total de rese√±as recibidas por el negocio. |
| `stars`       | double   | Promedio de estrellas basado en las rese√±as del negocio. |
| `state`       | string   | Estado donde se encuentra el negocio. |

#### **Archivo: `yelp_academic_dataset_review.json`**

| **Columna**   | **Tipo** | **Descripci√≥n** |
|---------------|----------|-----------------|
| `business_id` | string   | Identificador √∫nico del negocio al que pertenece la rese√±a. |
| `date`        | string   | Fecha en que se public√≥ la rese√±a. |

#### **Archivo: `yelp_academic_dataset_review.json`**

| **Columna**   | **Tipo** | **Descripci√≥n** |
|---------------|----------|-----------------|
| `business_id` | string   | Identificador √∫nico del negocio al que pertenece la rese√±a. |
| `cool`        | long     | N√∫mero de votos "cool" para la rese√±a. |
| `date`        | string   | Fecha en que se public√≥ la rese√±a. |
| `funny`       | long     | N√∫mero de votos "funny" para la rese√±a. |
| `review_id`   | string   | Identificador √∫nico de la rese√±a. |
| `stars`       | double   | Puntuaci√≥n de la rese√±a (de 1 a 5 estrellas). |
| `text`        | string   | Texto completo de la rese√±a escrita por el usuario. |
| `useful`      | long     | N√∫mero de votos "useful" para la rese√±a. |
| `user_id`     | string   | Identificador √∫nico del usuario que escribi√≥ la rese√±a. |

#### **Archivo: `yelp_academic_dataset_tip.json`**

| **Columna**        | **Tipo** | **Descripci√≥n** |
|--------------------|----------|-----------------|
| `business_id`      | string   | Identificador √∫nico del negocio al que pertenece el tip. |
| `compliment_count` | long     | N√∫mero de elogios (compliments) recibidos por el tip. |
| `date`             | string   | Fecha en que se public√≥ el tip. |
| `text`             | string   | Texto completo del tip escrito por el usuario. |
| `user_id`          | string   | Identificador √∫nico del usuario que escribi√≥ el tip. |

#### **Archivo: `yelp_academic_dataset_user.json`**

| **Columna**          | **Tipo** | **Descripci√≥n** |
|----------------------|----------|-----------------|
| `average_stars`      | double   | Promedio de estrellas que ha recibido el usuario en todas sus rese√±as. |
| `compliment_cool`    | long     | N√∫mero de elogios ("cool") que el usuario ha recibido. |
| `compliment_cute`    | long     | N√∫mero de elogios ("cute") que el usuario ha recibido. |
| `compliment_funny`   | long     | N√∫mero de elogios ("funny") que el usuario ha recibido. |
| `compliment_hot`     | long     | N√∫mero de elogios ("hot") que el usuario ha recibido. |
| `compliment_list`    | long     | N√∫mero de elogios ("list") que el usuario ha recibido. |
| `compliment_more`    | long     | N√∫mero de elogios ("more") que el usuario ha recibido. |
| `compliment_note`    | long     | N√∫mero de elogios ("note") que el usuario ha recibido. |
| `compliment_photos`  | long     | N√∫mero de elogios ("photos") que el usuario ha recibido. |
| `compliment_plain`   | long     | N√∫mero de elogios ("plain") que el usuario ha recibido. |
| `compliment_profile` | long     | N√∫mero de elogios ("profile") que el usuario ha recibido. |
| `compliment_writer`  | long     | N√∫mero de elogios ("writer") que el usuario ha recibido. |
| `cool`               | long     | N√∫mero total de veces que el usuario ha sido considerado "cool". |
| `elite`              | string   | A√±o(s) en que el usuario ha sido considerado "elite" (puede ser uno o varios, separados por comas). |
| `fans`               | long     | N√∫mero de "fans" que el usuario tiene. |
| `friends`            | string   | Lista de amigos del usuario (puede estar vac√≠a). |
| `funny`              | long     | N√∫mero total de veces que el usuario ha sido considerado "funny". |
| `name`               | string   | Nombre del usuario. |
| `review_count`       | long     | N√∫mero total de rese√±as que el usuario ha escrito. |
| `useful`             | long     | N√∫mero total de veces que las rese√±as del usuario han sido consideradas "√∫tiles". |
| `user_id`            | string   | Identificador √∫nico del usuario. |
| `yelping_since`      | string   | Fecha en la que el usuario comenz√≥ a usar Yelp. |


### ‚ñ™ Dificultad t√©cnica

Este trabajo represent√≥ un reto debido a la gran cantidad de datos.

Inicialmente deb√≠amos contar con una arquitectura para refinar la calidad de los datos durante cada proceso del proyecto.

- Usamos el patr√≥n *Medallion Architecture*, popularizado por **Databricks** como parte de su propuesta Lakehouse. Maneja tres niveles: primero se guardan los datos crudos en **bronze**, luego se limpian y normalizan en **silver** y, por √∫ltimo, se agregan y modelan en **gold** para que queden listos para utilidad del negocio.

Posteriormente, al tener la data sin procesar, deb√≠amos encontrar un sistema para almacenar grandes cantidades de datos.

- **HDFS** (Hadoop Distributed File System) fue nuestra soluci√≥n debido a su alta disponibilidad, almacenamiento distribuido y tolerante a fallos que Spark necesita para procesar eficientemente enormes vol√∫menes de datos.

Para el procesamiento necesit√°bamos una herramienta capaz de manejar tal volumen de datos (`etl_bronze_to_silver.ipynb`).

- Python tradicional y sus librer√≠as como NumPy y pandas no eran opci√≥n debido a los excesivos tiempos de demora.  
- Spark fue nuestra opci√≥n ideal, ya que permite procesar y modelar en paralelo los gigabytes de rese√±as de Yelp en un solo flujo, desde la limpieza en Delta Lake hasta el entrenamiento con MLlib, sin quedarse corto de memoria ni velocidad.  
- Probamos con Polars, donde tuvimos problemas porque produc√≠a error al realizar una operaci√≥n que requer√≠a m√°s memoria de la disponible. En nuestro caso ocurri√≥ al intentar mover grandes cantidades de datos entre Spark y pandas (`df_completo.toPandas()`). Aqu√≠ pandas carg√≥ todo a memoria y, por ser un caso de big data, caus√≥ problemas. Lo interesante es que este error, de alguna forma, afect√≥ la sesi√≥n actual de Spark; algunas de las operaciones que ejecut√≥ pandas o Polars relacionadas con el manejo de memoria pudieron haber afectado la estabilidad de la sesi√≥n.

El siguiente reto fue la elecci√≥n de un formato adecuado para guardar los datos; formatos tradicionales XLSX o CSV no eran opci√≥n.

- Usamos formato **Parquet** para aprovechar y mantener el esquema actual; adem√°s, est√° optimizado para Spark y es compatible con HDFS.  
- Al crear la sesi√≥n por defecto de Spark, la memoria para el executor y driver no era suficiente, ni la cantidad de particiones. Modificamos estos par√°metros y usamos **10 particiones**. En caso de no ajustar estos par√°metros, la memoria exced√≠a el 95 % disponible.  
- Parquet permiti√≥ que, para una pr√≥xima lectura, Spark maneje las particiones internamente y no sea necesario recorrerlas manualmente.  
- Adem√°s, posterior al *join* del dataset, este ocupaba **7.06 GB**; al guardar obtuvimos **3.27 GB** en formato Parquet.


### ‚ñ™ Creaci√≥n del modelo

#### üê≥ Razonamiento para encapsular el entorno en Docker

| **Necesidad** | **Riesgo sin contenedores** | **Soluci√≥n en `docker-compose.yml`** |
|--------------|-----------------------------|--------------------------------------|
| **Consistencia de versiones**<br>(Java 8, Hadoop 2.7.4, Spark 3.4, Delta 2.x) | Incompatibilidades de *classpath*, librer√≠as nativas y binarios Delta | Im√°genes oficiales fijan cada binario y dependencia. |
| **Asignaci√≥n estricta de memoria**<br>(8 GB driver / executor) | Spark local compite con procesos del host; *OOM* al leer 9 GB JSON | Variables de entorno `SPARK_WORKER_MEMORY`, `spark.driver.memory`, `spark.executor.memory`. |
| **Almacenamiento distribuido**<br>para 9 GB + de datos crudos | El FS local se vuelve cuello de botella y carece de tolerancia a fallos | `namenode` + `datanode` con HDFS (replicaci√≥n 1 para dev). |
| **Reproducibilidad de notebooks y CI/CD** | ‚ÄúIt works on my machine‚Äù. Sucedi√≥ y se dockeriz√≥. | Jupyter Lab con PySpark apuntando a `spark://spark:7077`. |
| **Exploraci√≥n √°gil de resultados** | Mover datos a BI externo implica costes y latencia | Superset lee directamente tablas Delta en HDFS. |

> **Resultado:** con `docker-compose up` cualquier colaborador lanza un *mini-cluster* id√©ntico y persistente.  
> Los datasets (`./data`), modelos (`./models`) y scripts (`./spark_jobs`) se comparten mediante *bind-mounts* y *named volumes*.

#### SparkSession con Delta Lake

```python
from pyspark.sql import SparkSession

spark = (
    SparkSession.builder
        .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension")
        .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")
        .config("spark.driver.memory", "8g")
        .config("spark.executor.memory", "8g")
        .getOrCreate()
)
```
#### Carga de la capa silver
```python
df = spark.read.parquet(

"hdfs://namenode:9000/datalake/silver/yelp/reviews")
```
> PDT: La ruta HDFS se resuelve gracias a spark.hadoop.fs.defaultFS inyectado desde el contenedor

#### Etiquetado binario para Sentiment‚ÄØAnalysis
```python
df = (df.filter(df.stars != 3) ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† # descarta neutras

.withColumn("label",

F.when(F.col("stars") >= 4, 1).otherwise(0)))
```


#### üìù Pipeline de NLP

| **Etapa** | **Componente MLlib** | **Motivo de uso** |
| :--: | --- | --- |
| 1 | **Tokenizer** | Divide texto en *tokens*. |
| 2 | **StopWordsRemover** | Elimina t√©rminos sin carga sem√°ntica (‚Äúthe‚Äù, ‚Äúde‚Äù, ‚Äúy‚Äù). |
| 3 | **NGram** *(n = 2)* | Captura contexto local (ej. ‚Äúmuy bueno‚Äù, ‚Äúno volver√©‚Äù). |
| 4 | **HashingTF** *(numFeatures ‚â§ 200 k)* | Proyecta *n-grams* a un espacio disperso de dimensi√≥n fija, independiente del vocabulario completo. |
| 5 | **IDF** | Aten√∫a *n-grams* comunes y resalta los distintivos de cada rese√±a. |
| 6 | **LogisticRegression** *(elasticNet = 0.5)* | Clasificador lineal robusto, r√°pido en alta dimensi√≥n, con probabilidades interpretables. |

**¬øPor qu√© Logistic Regression?**

- En textos cortos (~80 tokens/rese√±a) las **relaciones lineales** entre TF-IDF y polaridad funcionan muy bien.  
- Regularizaci√≥n L1/L2 ‚ü∂ *features* dispersas y menor *over-fitting*.  
- Optimizaci√≥n LBFGS paralela incluida en MLlib (no requiere *Transformers*).

---

#### üîç B√∫squeda de hiperpar√°metros y validaci√≥n cruzada

```python
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

param_grid = (
    ParamGridBuilder()
        .addGrid(lr.regParam,        [0.01, 0.05, 0.1])
        .addGrid(hashing.numFeatures, [100_000, 200_000])
        .build()
)

cv = CrossValidator(
    estimator          = pipeline,
    estimatorParamMaps = param_grid,
    evaluator          = MulticlassClassificationEvaluator(metricName="f1"),
    numFolds           = 3,   # 3-fold CV ‚Üí buen balance coste/calidad
    parallelism        = 4    # reparte combinaciones en los workers
)
```
- **RegParam** controla la fuerza de la regularizaci√≥n.

- Varia **numFeatures** para equilibrar colisiones de *hashing* vs. memoria.

- **3‚Äëfold CV** mantiene generalizaci√≥n sin triplicar en exceso el costo de c√≥mputo; parallelism=4 reparte las combinaciones en el worker.


#### Entrenamiento, evaluaci√≥n y persistencia

```python
# Split de entrenamiento / prueba
train, test = df.randomSplit([0.8, 0.2], seed=42)

# Ajuste con Cross-Validation
cv_model = cv.fit(train)

# Evaluaci√≥n en el set de prueba
f1 = evaluator.evaluate(cv_model.transform(test))
print(f"F1-score: {f1:.2f}")   # ‚âà 0.88
```
> Resultado: se alcanz√≥ un F1-score ‚âà 0.88.

```python
# Persistencia del modelo
cv_model.write().overwrite().save("file:///home/jovyan/models/yelp_lr_cv")

# Persistencia de predicciones (capa *gold*)
(
    cv_model.transform(df)
      .select("review_id", "prediction", "label")
      .write.mode("overwrite")
      .parquet("file:///home/jovyan/data/gold/reviews_sentiment_pred")
)
```
> file:// apunta al sistema de archivos del contenedor Jupyter; gracias al bind-mount ./models y ./data, los artefactos quedan disponibles tanto en el host como en Superset.

Usar Docker nos permiti√≥:

- **Aislar** las dependencias cr√≠ticas (Spark 3.4, Hadoop 2.7, Java 8, Delta‚ÄØ2.x) sin contaminar el entorno del desarrollador.
- **Garantizar** 8‚ÄØGB de RAM reales para Spark, evitando fallos por desbordes cuando el dataset completo (~7‚ÄØGB en Parquet) se materializa.
- **Persistir** resultados reproducibles y versionables (modelos, datasets *gold*) listos para BI.
    
    El pipeline NLP ‚Üí TF‚ÄëIDF ‚Üí Logistic Regression, validado con Cross Validation, ofrece una base robusta y r√°pida para detectar satisfacci√≥n vs. insatisfacci√≥n en millones de rese√±as, constituyendo el n√∫cleo anal√≠tico que da valor inmediato al negocio.



MongoDB se utiliz√≥ para guardar las predicciones (*gold*) generadas por el modelo, aprovechando su rendimiento con grandes vol√∫menes de datos y su escalabilidad.


1. En la misma carpeta de `reviews_sentiment_pred` creamos el archivo `cargamongo.py`.  
2. Desde **MongoDB Compass** definimos la base de datos `ProyectoBD` y la colecci√≥n `reviews_sentiment`, dejando la estructura lista para recibir documentos.  
3. Leemos todos los archivos Parquet con la librer√≠a **PyArrow**.  
4. Convertimos los datos a *DataFrame* de **pandas**, luego a una lista de diccionarios y los insertamos con `insert_many` de **PyMongo**.  
5. Obtenemos as√≠ una base de datos lista para an√°lisis en tiempo real y con capacidad de escalar conforme crezca la cantidad de predicciones.




La integraci√≥n de **Superset** nos permiti√≥ crear gr√°ficos y tableros basados en las predicciones del modelo:

1. **Clonar y levantar Superset**  
   - Clonamos el repositorio oficial.  
   - Ajustamos el `docker-compose.yml` y levantamos los servicios con **Docker Desktop**.

2. **Acceso local**  
   - Iniciamos Superset en `http://localhost:8088`.  
   - Tras autenticarnos, comenzamos a preparar los datos con Python.

3. **Exploraci√≥n inicial**  
   - Analizamos la columna `state`; contamos como ‚Äúestado‚Äù cualquier valor que aparezca m√°s de una vez y tenga longitud > 1 car√°cter.  
   - Resultado (diccionario abreviado ‚á©):  

     <details><summary>Estados detectados</summary>

     ```python
     ESTADOS = {
         'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas',
         'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware',
         'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',
         'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',
         'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',
         'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',
         'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada',
         'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York',
         'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',
         'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',
         'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah',
         'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia',
         'WI': 'Wisconsin', 'WY': 'Wyoming',
         'PENNSYLVANIA': 'Pennsylvania', 'FLORIDA': 'Florida', 'LOUISIANA': 'Louisiana',
         'TENNESSEE': 'Tennessee', 'INDIANA': 'Indiana', 'NEVADA': 'Nevada',
         'ILLINOIS': 'Illinois', 'CALIFORNIA': 'California', 'ARIZONA': 'Arizona',
         'MISSOURI': 'Missouri', 'DELAWARE': 'Delaware', 'IDAHO': 'Idaho'
     }
     ```
     </details>

4. **Enriquecimiento de datos**  
   - Hacemos un `JOIN` entre las predicciones almacenadas en **ProyectoBD** y la informaci√≥n de negocios v√≠a `business_id`.

5. **Conexi√≥n desde Superset**  
   - Usamos **SQLAlchemy** (`create_engine`) para conectar con PostgreSQL:  
     `superset:superset@localhost:5432/superset` (Superset no se conecta directo a MongoDB).

6. **Carga final**  
   - Guardamos la tabla como **`reviews_pred_joined`** en el esquema `public`.

7. **Creaci√≥n de dashboards**  
   - Registramos la base en Superset, dise√±amos los *charts* y los a√±adimos al dashboard interactivo.


### ‚ñ™ Herramientas y/o tecnolog√≠as empleadas

- **Arquitectura Medallion** para el flujo y guardado de datos durante el pipeline.  
- **HDFS** para almacenamiento de data cruda.  
- **Apache Spark** para procesamiento distribuido de datos.  
- **Particionamiento** para un guardado eficiente.  
- **Formato Parquet** para almacenamiento √≥ptimo y columnar.  
- **MLlib** para el modelado de *Machine Learning*.  
- **MongoDB** (NoSQL) para almacenar las predicciones de sentimiento en BSON y escalar sin problemas.  
  - **PyArrow**: lectura de archivos Parquet.  
  - **PyMongo**: conexi√≥n Python-MongoDB para inserci√≥n masiva.  
  - **MongoDB Compass**: GUI para administrar la base de datos y colecciones.  
- **Apache Superset**: plataforma de visualizaci√≥n para crear dashboards interactivos.  
  - **SQLAlchemy**: conexi√≥n entre Python y PostgreSQL para Superset.

  ### ‚ñ™ Arquitectura del proyecto y ETL

Descargamos de **Kaggle** los 5 archivos JSON y los almacenamos en **HDFS**; dentro de nuestra *Medallion Architecture* esta es la **capa *bronze***.  
Luego, extraemos dichos archivos y, mediante un proceso **ETL** con **Spark**, generamos un √∫nico dataset consolidado, particionado y guardado en formato **Parquet**. Con este paso conformamos la **capa *silver***, de la que se alimenta el modelo de *Machine Learning*.  
El resultado del modelo se almacena en **MongoDB**, lo que denominamos **capa *gold***, lista para ser consumida en gr√°ficos orientados al negocio.



![Diagrama de arquitectura](docs/arquitectura.png)


### ‚ñ™ Resultados obtenidos y an√°lisis de estos

**ETL**  
Se obtuvo un dataset unificado que contiene solo variables relevantes para los gr√°ficos visuales y para llevarlo a un modelo de ML. Adem√°s, el particionado y uso de formato Parquet aportaron significativamente a trabajar de forma m√°s √≥ptima y fluida.

**Modelo**  
El pipeline NLP usa Tokenizer, stop-words, bi-gramas, TF-IDF y Logistic Regression y logra un **F1 ‚âà 0.88**.  
Los datos son 7 GB de rese√±as de Yelp en HDFS etiquetadas como positivas (‚â• 4‚òÖ) y negativas (‚â§ 2‚òÖ).  
Todo corre en Spark 3.4 con Delta Lake dentro de un `docker-compose` que fija 8 GB de RAM para driver y executor y se reproduce igual en cualquier m√°quina.  
El modelo se guarda en `./models/yelp_lr_cv` y las predicciones *gold* en `./data/gold`.

**Insight de negocio**

1. En la primera visualizaci√≥n vemos los *top 10* negocios con mayor n√∫mero de fraudes detectados; aparecen marcas como **Starbucks** y **Subway**, mostrando que incluso los negocios famosos no se libran de cometer fraude.  
2. El segundo gr√°fico muestra la tendencia de discrepancias a lo largo de los a√±os: conforme avanza el tiempo, los negocios cometen fraude y, en ocasiones, disminuyen la pr√°ctica para no levantar sospechas constantes.  
3. El tercer gr√°fico presenta los *top 10* estados con mayor promedio de fraudes en negocios; si estamos en uno de ellos, es probable que el negocio que visitemos haya cometido fraude en alg√∫n momento.  
4. La cuarta gr√°fica muestra la distribuci√≥n de estados con reviews fraudulentas, indicando cu√°les cometieron m√°s o menos fraude a lo largo del tiempo.  
5. El √∫ltimo gr√°fico se√±ala el estado y restaurante con mayor cantidad de fraudes detectados, sugiriendo qu√© lugares es preferible evitar.

---

### ‚ñ™ Dificultades identificadas al momento de implementar la soluci√≥n

**ETL**  
La sesi√≥n base de Spark deb√≠a ser configurable y tuvimos que probar diversos valores de memoria para el executor, driver y n√∫mero de particiones; de lo contrario, la memoria alcanzaba el 100 % y el proceso se cortaba.

**Modelo**  
- Alinear versiones (Java 8, Hadoop 2.7.4, Spark 3.4, Delta 2.x) para evitar choques de *classpath*.  
- Los OOM al cargar 9 GB de JSON obligaron a fijar 8 GB de RAM para driver / executor.  
- El disco local se volvi√≥ cuello de botella y sin tolerancia a fallos, lo que motiv√≥ montar un `namenode` + `datanode` en HDFS.  
- La falta de reproducibilidad (‚Äúit works on my machine‚Äù) se resolvi√≥ contenedorizando todo con variables y vol√∫menes fijados.  
- Mover resultados a otras herramientas de BI a√±ad√≠a latencia; Superset pas√≥ a leer Delta en origen.  
- Ajustar `numFeatures` para equilibrar colisiones de *hashing* y uso de memoria exigi√≥ validar varias combinaciones.  
- La 3-fold CV multiplic√≥ el tiempo de c√≥mputo, mitigado con `parallelism = 4`.  
- Asegurar que modelos y datasets *gold* persistan fuera del contenedor requiri√≥ *bind-mounts* y *named volumes* bien configurados.

**Superset**  
Al tener una gran cantidad de datos, cada ejecuci√≥n pod√≠a demorar m√°s de 20 min antes de arrojar un error, haciendo los ciclos de prueba muy largos.

---

### ‚ñ™ Conclusiones y posibles mejoras

**Conclusiones**

1. **Data Yelp + NLP** permite clasificar satisfacci√≥n / insatisfacci√≥n autom√°ticamente, cubriendo la escasez de rese√±as fiables.  
2. 9 GB en bruto (5 archivos JSON) ‚Üí 3.27 GB Parquet tras ETL, imprescindible para procesados posteriores de modelo y visualizaci√≥n.  
3. La **Arquitectura Medallion** (Bronze ‚Üí Silver ‚Üí Gold) dio un orden claro al flujo de datos en cada etapa.  
4. **Modelo**: pipeline Tokenizer ‚Üí StopWords ‚Üí bi-gramas ‚Üí TF-IDF ‚Üí Logistic Regression validado con 3-fold CV; **F1 ‚âà 0.88**.

Comenzamos con 9 GB de rese√±as Yelp, empleamos la arquitectura Medallion en HDFS, Spark 3.4 dockerizado y el pipeline NLP ‚Üí TF-IDF ‚Üí Logistic Regression para clasificar satisfacci√≥n de clientes, guardar resultados en MongoDB y exponerlos en Superset. Este flujo permiti√≥ manejar adecuadamente el gran volumen de datos.

**Posibles mejoras**

- Guardar la data en **Amazon S3** y consultarla con **Athena**; la data se actualizar√≠a continuamente y las consultas ser√≠an m√°s eficientes usando √≠ndices por fecha.  
- Migrar el procesamiento a un cl√∫ster **Databricks**, orquestado por **Airflow**, programado para correr a una hora fija cada d√≠a y automatizar el pipeline completo.  
- Conectar los resultados a **Power BI** para ofrecer gr√°ficas actualizadas y de f√°cil acceso a los *stakeholders*.


**Extra**
- Podemos crear un modelo usando grafos ya que cada usuario tiene el id de su correspondiente amigo en la plataforma
- Redis puede aportar una pieza de baja latencia en la capa de servicio y monitoreo en tiempo real ya que los datos viven en la RAM del servidor